{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание: детекция людей на картинах (8 баллов + 3 дополнительных)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Скачайте датасет PeopleArt ([github](https://github.com/BathVisArtData/PeopleArt), [kaggle](https://www.kaggle.com/datasets/amanagr/people-art-dataset)), напишите `lightning.LightningDataModule` для работы с ним\n",
    "2. Реализуйте `lightning.LightningModule` для обучения детектора.\n",
    "3. Реализуйте расчёт и логирование метрик (mAP - обязательно, остальное - по желанию), можно использовать `torchmetrics` и любой понравившийся логгер (`tensorboard`, `aim`, `mlflow`, `wandb`, etc).\n",
    "4. Реализуйте обучение модели с сохранением чекпоинта\n",
    "5. Постарайтесь добиться mAP $\\gt$ 0.3 Можно использовать предобученные модели из `torchvision`\n",
    "6. В решении приложите к ноутбуку архив с логами и чекпоинтом модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Критерии оценки:\n",
    "1. (6 баллов) Реализованы модули для работы с данными и моделью и возможность запустить обучение и валидацию.\n",
    "2. (2 балла) Удалось добиться $mAP > 0.3$\n",
    "\n",
    "За что могут быть снижены баллы:\n",
    "1. Ваш ноутбук падает с ошибкой - проверьте перед отправкой, что при перезагрузке кернела и последовательном исполнении ячеек всё запускается. \n",
    "2. Неаккуратное оформление - без фанатизма, просто постарайтесь, чтобы не было огромных функций в 30+ строк без комментариев, переменных с именами в один символ, слишком много ячеек, где вы просто что-то отлаживаете без пояснений\n",
    "3. Не приложены логи и чекпоинты - без них будет сложно понять, что у вас получилось\n",
    "\n",
    "Советы:\n",
    "- если вы сможете большую часть своего кода вынести в `.py` файлы, а в ноутбуке будете их импортировать - будет совсем хорошо, тогда ноутбук получится лаконичным и чистым. \n",
    "- для автоматического форматирования ноутбуков есть полезный пакет `nbqa`, можно обработать финальную версию хотя бы так:\n",
    "  ```bash\n",
    "  nbqa isort peopleart_detection.ipynb\n",
    "  nbqa black peopleart_detection.ipynb\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы можно было использовать модели из `torchvision.models.detection`, нужно обеспечить правильный формат данных.\n",
    "\n",
    "`Dataloader` должен возвращать батчи вида `tuple[list[Tensor], list[dict[str, Tensor]]]`, то есть пару списков:\n",
    "- с изображениями (в виде тензоров, могут быть любого размера)\n",
    "- и соответствующей аннотацией (словари, где обязательно есть поля `boxes` и `labels`)\n",
    "\n",
    "Пример батча - ниже в переменной `batch`\n",
    "\n",
    "Для реализации модуля данных:\n",
    "1. Реализуйте подкласс `torch.utils.data.Dataset`, где будет реализован парсинг аннотаций (они в XML, вам пригодится пакет `xmltodict`) и сбор данных в пары изображение-аннотация, причём аннотации уже должны быть приведены в нужный формат, как в примере ниже, а метод `__getitem__` должен возвращать `tuple[Tensor, dict[str, Tensor]]`\n",
    "2. Реализуйте подкласс `lightning.LightningDataModule`, который будет создавать датасеты для подвыборок (train/val/test) и загрузчики данных для них. Для упаковки данных в батчи вам нужно будет определить аргумент `collate_fn` для `torch.utils.data.DataLoader`, иначе код будет падать при попытке сложить изображения разного размера.\n",
    "3. Примечание: если вы захотите описать свою модель без использования архитектур из `torchvision`, то на этапе упаковки в батчи было бы логично привести изображения к единому размеру, например сделать размер большей стороны равным $416$, а затем добавить zero padding для того, чтобы итоговый размер изображения был равен $416 \\times 416$. Это позволит обрабатывать батч параллельно на GPU. При этом аннотацию нужно изменить согласованным образом! В `albumentations` есть нужные трансформации, которые работают одновременно с изображением и разметкой, поищите их. При работе с детекторами из `torchvision` эти операции обычно делаются где-то внутри класса модели. Сможете найти их, например, для `SSD`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример данных: что-то такое может храниться внутри вашего класса для датасета, но сами изображения лучше читать с диска внутри метода `__getitem__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "takahashi = Image.open(requests.get(\"https://github.com/BathVisArtData/PeopleArt/blob/master/JPEGImages/Shin-hanga/shotei-takahashi_shore-of-lake-chuzenji.jpg?raw=true\", stream=True).raw)\n",
    "ralph = Image.open(requests.get(\"https://github.com/BathVisArtData/PeopleArt/blob/master/JPEGImages/Photorealism/ralph-goings_booth-group-1983.jpg?raw=true\", stream=True).raw)\n",
    "\n",
    "data_sample_batch = [\n",
    "    (\n",
    "        takahashi,\n",
    "        {\n",
    "            \"boxes\": torch.tensor(\n",
    "                [[240.0, 350.0, 268.0, 418.0], [204.0, 324.0, 229.0, 380.0]]\n",
    "            ),\n",
    "            \"labels\": torch.tensor([1, 1]),\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        ralph,\n",
    "        {\n",
    "            \"boxes\": torch.tensor(\n",
    "                [\n",
    "                    [255.0, 51.0, 400.0, 267.0],\n",
    "                    [24.0, 70.0, 187.0, 341.0],\n",
    "                    [112.0, 54.0, 220.0, 294.0],\n",
    "                ]\n",
    "            ),\n",
    "            \"labels\": torch.tensor([1, 1, 1]),\n",
    "        },\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно посмотреть на пример изображений с аннотациями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot open resource",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vsevo\\MKN\\3rd year\\DL\\dl-mkn\\assignments\\peopleart_detection.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fig, axes \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(ncols\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(data_sample_batch), figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m7\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m sample, ax \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(data_sample_batch, axes):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# нарисуем рамки\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     detection \u001b[39m=\u001b[39m draw_bounding_boxes(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         transforms\u001b[39m.\u001b[39;49mCompose([transforms\u001b[39m.\u001b[39;49mToTensor(), transforms\u001b[39m.\u001b[39;49mConvertImageDtype(torch\u001b[39m.\u001b[39;49muint8)])(sample[\u001b[39m0\u001b[39;49m]),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         boxes\u001b[39m=\u001b[39;49msample[\u001b[39m1\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mboxes\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         width\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         font\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mArial\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         font_size\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         colors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mred\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     detection: Image\u001b[39m.\u001b[39mImage \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mToPILImage()(detection)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     ax\u001b[39m.\u001b[39mimshow(detection)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\torchvision\\utils.py:226\u001b[0m, in \u001b[0;36mdraw_bounding_boxes\u001b[1;34m(image, boxes, labels, colors, fill, width, font, font_size)\u001b[0m\n\u001b[0;32m    224\u001b[0m     txt_font \u001b[39m=\u001b[39m ImageFont\u001b[39m.\u001b[39mload_default()\n\u001b[0;32m    225\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 226\u001b[0m     txt_font \u001b[39m=\u001b[39m ImageFont\u001b[39m.\u001b[39;49mtruetype(font\u001b[39m=\u001b[39;49mfont, size\u001b[39m=\u001b[39;49mfont_size \u001b[39mor\u001b[39;49;00m \u001b[39m10\u001b[39;49m)\n\u001b[0;32m    228\u001b[0m \u001b[39m# Handle Grayscale images\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m image\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\PIL\\ImageFont.py:791\u001b[0m, in \u001b[0;36mtruetype\u001b[1;34m(font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[0;32m    788\u001b[0m     \u001b[39mreturn\u001b[39;00m FreeTypeFont(font, size, index, encoding, layout_engine)\n\u001b[0;32m    790\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 791\u001b[0m     \u001b[39mreturn\u001b[39;00m freetype(font)\n\u001b[0;32m    792\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[0;32m    793\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_path(font):\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\PIL\\ImageFont.py:788\u001b[0m, in \u001b[0;36mtruetype.<locals>.freetype\u001b[1;34m(font)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfreetype\u001b[39m(font):\n\u001b[1;32m--> 788\u001b[0m     \u001b[39mreturn\u001b[39;00m FreeTypeFont(font, size, index, encoding, layout_engine)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\PIL\\ImageFont.py:226\u001b[0m, in \u001b[0;36mFreeTypeFont.__init__\u001b[1;34m(self, font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[0;32m    224\u001b[0m                 load_from_bytes(f)\n\u001b[0;32m    225\u001b[0m             \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfont \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39;49mgetfont(\n\u001b[0;32m    227\u001b[0m         font, size, index, encoding, layout_engine\u001b[39m=\u001b[39;49mlayout_engine\n\u001b[0;32m    228\u001b[0m     )\n\u001b[0;32m    229\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     load_from_bytes(font)\n",
      "\u001b[1;31mOSError\u001b[0m: cannot open resource"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(ncols=len(data_sample_batch), figsize=(10, 7))\n",
    "for sample, ax in zip(data_sample_batch, axes):\n",
    "    # нарисуем рамки\n",
    "    detection = draw_bounding_boxes(\n",
    "        transforms.Compose([transforms.ToTensor(), transforms.ConvertImageDtype(torch.uint8)])(sample[0]),\n",
    "        boxes=sample[1][\"boxes\"],\n",
    "        width=3,\n",
    "        font=\"Arial\",\n",
    "        font_size=15,\n",
    "        colors=\"red\",\n",
    "    )\n",
    "    detection: Image.Image = torchvision.transforms.ToPILImage()(detection)\n",
    "    ax.imshow(detection)\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот как должен выглядеть батч:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.ToTensor()\n",
    "image_tensors = [image_transform(x) for x, _ in data_sample_batch]\n",
    "labels = [y for _, y in data_sample_batch]\n",
    "\n",
    "batch = (image_tensors, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[[0.8353, 0.8275, 0.8353,  ..., 0.8588, 0.8588, 0.8471],\n",
       "           [0.8275, 0.8235, 0.8353,  ..., 0.8549, 0.8549, 0.8471],\n",
       "           [0.8157, 0.8196, 0.8275,  ..., 0.8510, 0.8510, 0.8431],\n",
       "           ...,\n",
       "           [0.9294, 0.8784, 0.7765,  ..., 0.7961, 0.8039, 0.8078],\n",
       "           [0.9216, 0.8863, 0.7882,  ..., 0.8118, 0.8118, 0.8118],\n",
       "           [0.9255, 0.8941, 0.8039,  ..., 0.8078, 0.8039, 0.7922]],\n",
       "  \n",
       "          [[0.8078, 0.7922, 0.7725,  ..., 0.7961, 0.8000, 0.7961],\n",
       "           [0.8000, 0.7882, 0.7725,  ..., 0.7882, 0.7922, 0.7961],\n",
       "           [0.7765, 0.7686, 0.7608,  ..., 0.7804, 0.7804, 0.7843],\n",
       "           ...,\n",
       "           [0.9373, 0.8824, 0.7490,  ..., 0.7373, 0.7451, 0.7529],\n",
       "           [0.9294, 0.8902, 0.7608,  ..., 0.7529, 0.7529, 0.7569],\n",
       "           [0.9333, 0.8980, 0.7765,  ..., 0.7490, 0.7451, 0.7373]],\n",
       "  \n",
       "          [[0.6353, 0.6314, 0.6392,  ..., 0.5961, 0.5843, 0.5804],\n",
       "           [0.6353, 0.6353, 0.6431,  ..., 0.6078, 0.6000, 0.5922],\n",
       "           [0.6392, 0.6353, 0.6431,  ..., 0.6314, 0.6235, 0.6235],\n",
       "           ...,\n",
       "           [0.8941, 0.8275, 0.6784,  ..., 0.6157, 0.6157, 0.6157],\n",
       "           [0.8863, 0.8353, 0.6902,  ..., 0.6314, 0.6235, 0.6196],\n",
       "           [0.8902, 0.8431, 0.7059,  ..., 0.6275, 0.6157, 0.6000]]]),\n",
       "  tensor([[[0.8980, 0.9020, 0.9098,  ..., 0.9216, 0.9176, 0.9137],\n",
       "           [0.8667, 0.8745, 0.8824,  ..., 0.8824, 0.8824, 0.8824],\n",
       "           [0.8784, 0.8824, 0.8863,  ..., 0.8549, 0.8588, 0.8627],\n",
       "           ...,\n",
       "           [0.9020, 0.8941, 0.8902,  ..., 0.9137, 0.9137, 0.9176],\n",
       "           [0.8980, 0.8980, 0.8902,  ..., 0.9098, 0.9098, 0.9137],\n",
       "           [0.8941, 0.8941, 0.8941,  ..., 0.9098, 0.9137, 0.9216]],\n",
       "  \n",
       "          [[0.8353, 0.8392, 0.8471,  ..., 0.8706, 0.8667, 0.8627],\n",
       "           [0.8039, 0.8118, 0.8196,  ..., 0.8314, 0.8314, 0.8314],\n",
       "           [0.8157, 0.8196, 0.8235,  ..., 0.8039, 0.8078, 0.8118],\n",
       "           ...,\n",
       "           [0.8471, 0.8392, 0.8353,  ..., 0.8627, 0.8627, 0.8667],\n",
       "           [0.8431, 0.8431, 0.8353,  ..., 0.8588, 0.8588, 0.8627],\n",
       "           [0.8392, 0.8392, 0.8392,  ..., 0.8588, 0.8627, 0.8706]],\n",
       "  \n",
       "          [[0.7765, 0.7804, 0.7882,  ..., 0.8078, 0.8039, 0.8000],\n",
       "           [0.7451, 0.7529, 0.7608,  ..., 0.7686, 0.7686, 0.7686],\n",
       "           [0.7569, 0.7608, 0.7647,  ..., 0.7412, 0.7451, 0.7490],\n",
       "           ...,\n",
       "           [0.7451, 0.7373, 0.7333,  ..., 0.7882, 0.7882, 0.7922],\n",
       "           [0.7412, 0.7412, 0.7333,  ..., 0.7843, 0.7843, 0.7882],\n",
       "           [0.7373, 0.7373, 0.7373,  ..., 0.7843, 0.7882, 0.7961]]])],\n",
       " [{'boxes': tensor([[240., 350., 268., 418.],\n",
       "           [204., 324., 229., 380.]]),\n",
       "   'labels': tensor([1, 1])},\n",
       "  {'boxes': tensor([[255.,  51., 400., 267.],\n",
       "           [ 24.,  70., 187., 341.],\n",
       "           [112.,  54., 220., 294.]]),\n",
       "   'labels': tensor([1, 1, 1])}])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([[240., 350., 268., 418.],\n",
       "          [204., 324., 229., 380.]]),\n",
       "  'labels': tensor([1, 1])},\n",
       " {'boxes': tensor([[255.,  51., 400., 267.],\n",
       "          [ 24.,  70., 187., 341.],\n",
       "          [112.,  54., 220., 294.]]),\n",
       "  'labels': tensor([1, 1, 1])}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модели из `torchvision`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разберём для примера `SSD`, вы можете взять любую другую модель, в том числе написать всё самостоятельно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/ssdlite320_mobilenet_v3_large_coco-a79551df.pth\" to C:\\Users\\vsevo/.cache\\torch\\hub\\checkpoints\\ssdlite320_mobilenet_v3_large_coco-a79551df.pth\n",
      "100%|██████████| 13.4M/13.4M [00:00<00:00, 26.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.detection import ssdlite320_mobilenet_v3_large, SSDLite320_MobileNet_V3_Large_Weights\n",
    "\n",
    "# создадим модель с весами COCO\n",
    "weights = SSDLite320_MobileNet_V3_Large_Weights.COCO_V1\n",
    "ssd = ssdlite320_mobilenet_v3_large(weights=weights)\n",
    "\n",
    "# получим батч\n",
    "image_transform = weights.transforms()\n",
    "image_tensors = [image_transform(x) for x, _ in data_sample_batch]\n",
    "labels = [y for _, y in data_sample_batch]\n",
    "batch = (image_tensors, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод модели в режиме инференса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['boxes', 'scores', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "ssd.eval()\n",
    "preds = ssd.forward(image_tensors)\n",
    "print(preds[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отрисуем предсказания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot open resource",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vsevo\\MKN\\3rd year\\DL\\dl-mkn\\assignments\\peopleart_detection.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m scores \u001b[39m=\u001b[39m prediction[\u001b[39m\"\u001b[39m\u001b[39mscores\u001b[39m\u001b[39m\"\u001b[39m][mask]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# нарисуем рамки\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m detection \u001b[39m=\u001b[39m draw_bounding_boxes(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     transforms\u001b[39m.\u001b[39;49mCompose([transforms\u001b[39m.\u001b[39;49mToTensor(), transforms\u001b[39m.\u001b[39;49mConvertImageDtype(torch\u001b[39m.\u001b[39;49muint8)])(sample[\u001b[39m0\u001b[39;49m]),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     boxes\u001b[39m=\u001b[39;49mboxes,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X24sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     labels\u001b[39m=\u001b[39;49m[\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mclasses[\u001b[39mint\u001b[39;49m(label)]\u001b[39m}\u001b[39;49;00m\u001b[39m: \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mfloat\u001b[39;49m(score)\u001b[39m:\u001b[39;49;00m\u001b[39m.2f\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39mfor\u001b[39;49;00m label, score \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(pred_labels, scores)],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     width\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     font\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mArial\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     font_size\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     colors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mred\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X24sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m detection: Image\u001b[39m.\u001b[39mImage \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mToPILImage()(detection)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/vsevo/MKN/3rd%20year/DL/dl-mkn/assignments/peopleart_detection.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m ax\u001b[39m.\u001b[39mimshow(detection)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\torchvision\\utils.py:226\u001b[0m, in \u001b[0;36mdraw_bounding_boxes\u001b[1;34m(image, boxes, labels, colors, fill, width, font, font_size)\u001b[0m\n\u001b[0;32m    224\u001b[0m     txt_font \u001b[39m=\u001b[39m ImageFont\u001b[39m.\u001b[39mload_default()\n\u001b[0;32m    225\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 226\u001b[0m     txt_font \u001b[39m=\u001b[39m ImageFont\u001b[39m.\u001b[39;49mtruetype(font\u001b[39m=\u001b[39;49mfont, size\u001b[39m=\u001b[39;49mfont_size \u001b[39mor\u001b[39;49;00m \u001b[39m10\u001b[39;49m)\n\u001b[0;32m    228\u001b[0m \u001b[39m# Handle Grayscale images\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m image\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\PIL\\ImageFont.py:791\u001b[0m, in \u001b[0;36mtruetype\u001b[1;34m(font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[0;32m    788\u001b[0m     \u001b[39mreturn\u001b[39;00m FreeTypeFont(font, size, index, encoding, layout_engine)\n\u001b[0;32m    790\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 791\u001b[0m     \u001b[39mreturn\u001b[39;00m freetype(font)\n\u001b[0;32m    792\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[0;32m    793\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_path(font):\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\PIL\\ImageFont.py:788\u001b[0m, in \u001b[0;36mtruetype.<locals>.freetype\u001b[1;34m(font)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfreetype\u001b[39m(font):\n\u001b[1;32m--> 788\u001b[0m     \u001b[39mreturn\u001b[39;00m FreeTypeFont(font, size, index, encoding, layout_engine)\n",
      "File \u001b[1;32mc:\\python\\Lib\\site-packages\\PIL\\ImageFont.py:226\u001b[0m, in \u001b[0;36mFreeTypeFont.__init__\u001b[1;34m(self, font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[0;32m    224\u001b[0m                 load_from_bytes(f)\n\u001b[0;32m    225\u001b[0m             \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfont \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39;49mgetfont(\n\u001b[0;32m    227\u001b[0m         font, size, index, encoding, layout_engine\u001b[39m=\u001b[39;49mlayout_engine\n\u001b[0;32m    228\u001b[0m     )\n\u001b[0;32m    229\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     load_from_bytes(font)\n",
      "\u001b[1;31mOSError\u001b[0m: cannot open resource"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = weights.meta[\"categories\"]\n",
    "\n",
    "fig, axes = plt.subplots(ncols=len(data_sample_batch), figsize=(10, 7))\n",
    "for sample, prediction, ax in zip(data_sample_batch, preds, axes):\n",
    "    # выберем только объекты с оценкой уверенности >= 0.2 и соответствующие классу person\n",
    "    mask = (prediction[\"scores\"] >= 0.2) * (prediction[\"labels\"] == 1)\n",
    "    boxes = prediction[\"boxes\"][mask]\n",
    "    pred_labels = prediction[\"labels\"][mask]\n",
    "    scores = prediction[\"scores\"][mask]\n",
    "    # нарисуем рамки\n",
    "    detection = draw_bounding_boxes(\n",
    "        transforms.Compose([transforms.ToTensor(), transforms.ConvertImageDtype(torch.uint8)])(sample[0]),\n",
    "        boxes=boxes,\n",
    "        labels=[f\"{classes[int(label)]}: {float(score):.2f}\" for label, score in zip(pred_labels, scores)],\n",
    "        width=3,\n",
    "        font=\"Arial\",\n",
    "        font_size=15,\n",
    "        colors=\"red\",\n",
    "    )\n",
    "    detection: Image.Image = torchvision.transforms.ToPILImage()(detection)\n",
    "    ax.imshow(detection)\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод модели в режиме обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bbox_regression': tensor(2.3090, grad_fn=<DivBackward0>), 'classification': tensor(2.4574, grad_fn=<DivBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "ssd.train()\n",
    "preds = ssd.forward(image_tensors, labels)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель возвращает уже рассчитанные значения ошибок, то есть для обучения почти всё готово.\n",
    "\n",
    "Вам останется только обернуть такую модель в `LightningModule`, добавив расчёт метрик и логирование.\n",
    "\n",
    "Будьте внимательны: некоторые модели из `torchvision` (`SSD` в частности) в качестве нулевого класса заводят специальный класс `__background__`, поэтому перед запуском обучения убедитесь, что ваша разметка из датамодуля приведена в соответствие с разметкой, которую будет возвращать модель.\n",
    "\n",
    "Полезная штука для дебага: аргумент `overfit_batches` в `lightning.Trainer`, попробуйте переобучить модель на одном батче и отследите, что ваши метрики растут, приближаясь к 100% точности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бонус (3 балла): YoloV8 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разберитесь, как обучить `YoloV8` из пакета `ultralytics` на нашем датасете. Инструкция есть здесь: https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/\n",
    "\n",
    "Здесь главное - правильно подготовить данные, нас интересует раздел `1. Create Dataset`, под спойлером `Or manually prepare your dataset`.\n",
    "\n",
    "Критерий оценки: архив с\n",
    "1. `dataset.yaml` файлом с настройками датасета\n",
    "2. логи экспериментов и чекпоинт модели\n",
    "3. ваш код с запуском обучения (python / bash скрипт или jupyter notebook)\n",
    "\n",
    "Сравните результаты с моделью из обязательной части, напишите кратко, что вы по этому поводу думаете (почему лучше/хуже, что можно попробовать поменять)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
